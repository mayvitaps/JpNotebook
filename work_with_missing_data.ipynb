{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first dataset\n",
    "df = pd.read_csv('eda_missing_data_dataset1.csv')\n",
    "\n",
    "# Print the first 5 rows of dataset 1\n",
    "df.head()\n",
    "\n",
    "df.shape\n",
    "\n",
    "# Read in second dataset\n",
    "df_zip = pd.read_csv('eda_missing_data_dataset2.csv')\n",
    "\n",
    "# Print the first 5 rows of dataset 2\n",
    "df_zip.head()\n",
    "\n",
    "df_zip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-join the two datasets\n",
    "df_joined = df.merge(df_zzip, how= 'left', on = ['date', 'center_point_geom'])\n",
    "\n",
    "# Print the first 5 rows of the merged data\n",
    "df_joined.head()\n",
    "\n",
    "# Get descriptive statistics of the joined dataframe\n",
    "df_joined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df of just the rows that are missing data\n",
    "df_null_geo = df_joined[pd.isnumm(df_joined.state_code)]\n",
    "df_null_geo.shape\n",
    "\n",
    "# Get non-null counts on merged dataframe\n",
    "df_joined.info()\n",
    "\n",
    "# Print the first 5 rows\n",
    "df_null_geo.head()\n",
    "\n",
    "# Create new df of just latitude, longitude, and number of strikes and group by latitude and longitude\n",
    "top_missing = df_null_geo[['latitude','longitude','number_of_strikes_x']\n",
    "            ].groupby(['latitude','longitude']\n",
    "                      ).sum().sort_values('number_of_strikes_x',ascending=False).reset_index()\n",
    "top_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px  # Be sure to import express\n",
    "# reduce size of db otherwise it could break\n",
    "fig = px.scatter_geo(top_missing[top_missing.number_of_strikes_x>=300],  # Input Pandas DataFrame\n",
    "                    lat=\"latitude\",  # DataFrame column with latitude\n",
    "                    lon=\"longitude\",  # DataFrame column with latitude\n",
    "                    size=\"number_of_strikes_x\") # Set to plot size as number of strikes\n",
    "fig.update_layout(\n",
    "    title_text = 'Missing data', # Create a Title\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px  # Be sure to import express\n",
    "fig = px.scatter_geo(top_missing[top_missing.number_of_strikes_x>=300],  # Input Pandas DataFrame\n",
    "                    lat=\"latitude\",  # DataFrame column with latitude\n",
    "                    lon=\"longitude\",  # DataFrame column with latitude\n",
    "                    size=\"number_of_strikes_x\") # Set to plot size as number of strikes\n",
    "fig.update_layout(\n",
    "    title_text = 'Missing data', # Create a Title\n",
    "    geo_scope='usa',  # Plot only the USA instead of globe\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define df1\n",
    "data = {'planet': ['Mercury', 'Venus', 'Earth', 'Mars',\n",
    "                    'Jupiter', 'Saturn', 'Uranus', 'Neptune'],\n",
    "        'radius_km': [2440, 6052, 6371, 3390, 69911, 58232,\n",
    "                      25362, 24622],\n",
    "        'moons': [0, 0, 1, 2, 80, 83, 27, 14]\n",
    "         }\n",
    "df1 = pd.DataFrame(data)\n",
    "df1\n",
    "\n",
    "# Define df2\n",
    "data = {'planet': ['Mercury', 'Venus', 'Earth', 'Meztli', 'Janssen'],\n",
    "        'radius_km': [2440, 6052, 6371, 48654, 11959],\n",
    "        'life?': ['no', 'no', 'yes', 'no', 'yes'],\n",
    "         }\n",
    "df2 = pd.DataFrame(data)\n",
    "df2\n",
    "\n",
    "merged = df1.merge(df2, how='left', on=['planet', 'radius_km'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_csv('eda_outliers_dataset1.csv')\n",
    "\n",
    "# Print first 10 rows\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "def readable_numbers(x):\n",
    "    \"\"\"takes a large number and formats it into K,M to make it more readable\"\"\"\n",
    "    if x >= 1e6:\n",
    "        s = '{:1.1f}M'.format(x*1e-6)\n",
    "    else:\n",
    "        s = '{:1.0f}K'.format(x*1e-3)\n",
    "    return s\n",
    "\n",
    "# Use the readable_numbers() function to create a new column \n",
    "df['number_of_strikes_readable']=df['number_of_strikes'].apply(readable_numbers)\n",
    "\n",
    "print(\"Mean:\" + readable_numbers(np.mean(df['number_of_strikes'])))\n",
    "print(\"Median:\" + readable_numbers(np.median(df['number_of_strikes'])))\n",
    "\n",
    "# Create boxplot\n",
    "box = sns.boxplot(x=df['number_of_strikes'])\n",
    "g = plt.gca()\n",
    "box.set_xticklabels(np.array([readable_numbers(x) for x in g.get_xticks()]))\n",
    "plt.xlabel('Number of strikes')\n",
    "plt.title('Yearly number of lightning strikes');\n",
    "\n",
    "# Calculate 25th percentile of annual strikes\n",
    "percentile25 = df['number_of_strikes'].quantile(0.25)\n",
    "\n",
    "# Calculate 75th percentile of annual strikes\n",
    "percentile75 = df['number_of_strikes'].quantile(0.75)\n",
    "\n",
    "# Calculate interquartile range\n",
    "iqr = percentile75 - percentile25\n",
    "\n",
    "# Calculate upper and lower thresholds for outliers\n",
    "upper_limit = percentile75 + 1.5 * iqr\n",
    "lower_limit = percentile25 - 1.5 * iqr\n",
    "\n",
    "print('Lower limit is: '+ readable_numbers(lower_limit))\n",
    "\n",
    "# Isolate outliers on low end\n",
    "df[df['number_of_strikes'] < lower_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(x[i]-0.5, y[i]+500000, s=readable_numbers(y[i]))\n",
    "\n",
    "colors = np.where(df['number_of_strikes'] < lower_limit, 'r', 'b')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(df['year'], df['number_of_strikes'],c=colors)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of strikes')\n",
    "ax.set_title('Number of lightning strikes by year')\n",
    "addlabels(df['year'], df['number_of_strikes'])\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `date` column to datetime\n",
    "df_2019['date']= pd.to_datetime(df_2019['date'])\n",
    "\n",
    "# Create 2 new columns\n",
    "df_2019['month'] = df_2019['date'].dt.month\n",
    "df_2019['month_txt'] = df_2019['date'].dt.month_name().str.slice(stop=3)\n",
    "\n",
    "# Group by `month` and `month_txt`, sum it, and sort. Assign result to new df\n",
    "df_2019_by_month = df_2019.groupby(['month','month_txt']).sum().sort_values('month', ascending=True).head(12).reset_index()\n",
    "df_2019_by_month\n",
    "\n",
    "# Read in 1987 data\n",
    "df_1987 = pd.read_csv('eda_outliers_dataset3.csv')\n",
    "\n",
    "# Convert `date` column to datetime\n",
    "df_1987['date'] = pd.to_datetime(df_1987['date'])\n",
    "\n",
    "# Create 2 new columns\n",
    "df_1987['month'] = df_1987['date'].dt.month\n",
    "df_1987['month_txt'] = df_1987['date'].dt.month_name().str.slice(stop=3)\n",
    "\n",
    "# Group by `month` and `month_txt`, sum it, and sort. Assign result to new df\n",
    "df_1987_by_month = df_1987.groupby(['month','month_txt']).sum().sort_values('month', ascending=True).head(12).reset_index()\n",
    "df_1987_by_month\n",
    "\n",
    "# Create new df that removes outliers\n",
    "df_without_outliers = df[df['number_of_strikes'] >= lower_limit]\n",
    "\n",
    "# Recalculate mean and median values on data without outliers\n",
    "print(\"Mean:\" + readable_numbers(np.mean(df_without_outliers['number_of_strikes'])))\n",
    "print(\"Median:\" + readable_numbers(np.median(df_without_outliers['number_of_strikes'])))\n",
    "\n",
    "# Convert `date` column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create new `month` column\n",
    "df['month'] = df['date'].dt.month_name().str.slice(stop=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical designations\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Encode `month` column as categoricals \n",
    "df['month'] = pd.Categorical(df['month'], categories=months, ordered=True)\n",
    "\n",
    "# Create `year` column by extracting the year info from the datetime object\n",
    "df['year'] = df['date'].dt.strftime('%Y')\n",
    "\n",
    "# Create a new df of month, year, total strikes\n",
    "df_by_month = df.groupby(['year', 'month']).sum(numeric_only=True).reset_index()\n",
    "df_by_month.head()\n",
    "\n",
    "# NOTE: In pandas v.2.X+ you must set 'numeric_only=True' or else the sum() function will throw an error\n",
    "\n",
    "# Create a new column that categorizes number_of_strikes into 1 of 4 categories\n",
    "df_by_month['strike_level'] = pd.qcut(\n",
    "    df_by_month['number_of_strikes'],\n",
    "    4,\n",
    "    labels = ['Mild', 'Scattered', 'Heavy', 'Severe'])\n",
    "df_by_month.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
